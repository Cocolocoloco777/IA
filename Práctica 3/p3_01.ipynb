{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ea7978-87e1-4f62-941b-372adc4972f2",
   "metadata": {},
   "source": [
    "# Práctica de aprendizaje automático (parte 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995aeb7-cabe-4769-8892-fae24a8ac39c",
   "metadata": {},
   "source": [
    "# Teorema de Bayes y Naïve Bayes (1.5 puntos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50a1f4",
   "metadata": {},
   "source": [
    "## 1. Teorema de Bayes\n",
    "\n",
    "El **Teorema de Bayes**:\n",
    "$$\n",
    "P(H_1 \\mid D, I) = \\frac{P(D \\mid H_1, I) \\times P(H_1 \\mid I)}{P(D \\mid I)} \\quad \\text{con} \\quad P(D \\mid I) = \\sum_i P(D \\mid H_i, I) \\times P(H_i \\mid I).\n",
    "$$\n",
    "\n",
    "- **$H_1$** = Hipótesis 1, **$D$** = datos, **$I$** = información.\n",
    "\n",
    "- **$P(H_1 \\mid I)$**: Probabilidad a *priori* de la hipótesis 1 (antes de observar los datos).\n",
    "- **$P(D \\mid I)$**: Evidencia de los datos.\n",
    "- **$P(D \\mid H_1, I)$**: *Verosimilitud* de la hipótesis 1 dados los datos.\n",
    "- **$P(H_1 \\mid D, I)$**: Probabilidad a *posteriori* de la hipótesis 1 (después de observar los datos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57344cae",
   "metadata": {},
   "source": [
    "### Ejercicio 1 - Palabra sospechosa en correo\n",
    "Vamos a calcular la probabilidad de que un correo sea **SPAM** dadas las palabras **\"gratis\"** y **\"oferta\"**. Supongamos que dado un nuevo correo, la probabilidad a priori de que sea **SPAM** es del **20%**.\n",
    "\n",
    "Si aparece la palabra **\"gratis\"**:\n",
    "- $P(\\text{\"gratis\"}\\mid\\text{SPAM})=0.4$\n",
    "- $P(\\text{\"gratis\"}\\mid \\neg \\text{SPAM})=0.05$\n",
    "- \n",
    "Si aparece la palabra **\"oferta\"**:\n",
    "- $P(\\text{\"oferta\"}\\mid\\text{SPAM})=0.7$\n",
    "- $P(\\text{\"oferta\"}\\mid \\neg \\text{SPAM})=0.05$\n",
    "\n",
    "1. Calcula $P(\\text{SPAM}\\mid\\text{\"gratis\"})$.\n",
    "2. ¿Qué ocurre si además ves la palabra **\"oferta\"** y asumes independencia? (Pista: multiplica verosimilitudes.)\n",
    "\n",
    "\n",
    "Completa y ejecuta la celda de abajo. Además, justifica razonadamente el resultado que obtengas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292398d7",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "\n",
    "##### Apartado 1\n",
    "Para calcular $ P(SPAM|``gratis\", I)$, utilizamos la fórmula del Teorema de Bayes. De modo que llamamos $H_1$ a la hipótesis de SPAM. Y $D$ es que aparezca la palabra \"gratis\". Luego\n",
    "$$P(SPAM|''gratis\", I)=\\frac{P(``gratis\"| SPAM, I)\\times P(SPAM, I)}{P(``gratis\"| I)}$$\n",
    "\n",
    "\n",
    "A su vez, sabemos que $P(``gratis\"|I)=\\sum P(``gratis\"|H_i,I)\\times P(H_1|I)$. Como en este caso, solo tenemos $H_1$ y $H_2$, siendo $H_2$ que el correo no sea SPAM, entonces\n",
    "$$P(``gratis\",I)=P(``gratis\"|SPAM,I)\\times P(SPAM,I)+P(``gratis\"|NO\\_SPAM)\\times P(NO\\_SPAM,I)$$\n",
    "\n",
    "Con todo lo anterior, calculamos la probabilidad.\n",
    "\n",
    "##### Apartado 2\n",
    "Por otro lado, en el caso de ver tambień en el correo la palabra \"oferta\", debemos tratarlas, como nos especifica el enunciado como variables independientes. Luego calcularemos la verosimilitud como la multiplicación de ambas:\n",
    "$$P(``oferta\", ``gratis\"|SPAM,I)=P(``oferta\"|SPAM,I)\\cdot P(``gratis\"|SPAM,I)$$\n",
    "\n",
    "Luego, la probabilidad a posteriori vendrá dada por:\n",
    "$$P(SPAM|``oferta\", ``gratis\",I)=\\frac{P(``oferta\", ``gratis\"|SPAM,I)\\times P(SPAM;I)}{P(``oferta\",``gratis\",I)}$$\n",
    "con \n",
    "$$P(``oferta\",``gratis\",I)=P(``oferta\", ``gratis\"|SPAM,I)\\cdot P(SPAM,I)+P(``oferta\", ``gratis\"|NO\\_SPAM)\\cdot P(NO\\_SPAM)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95eaf55-ce4d-4511-8eab-69c2c2da50de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(SPAM | 'gratis') = 0.666667  (~66.67%)\n",
      "P(SPAM | 'gratis' y 'oferta') = 0.965517  (~96.55%)\n"
     ]
    }
   ],
   "source": [
    "p_spam = 0.2\n",
    "p_no_spam = 1 - p_spam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "\n",
    "p_gratis_spam = 0.4\n",
    "p_gratis_no_spam  = 0.05\n",
    "p_oferta_spam = 0.7\n",
    "p_oferta_no_spam  = 0.05\n",
    "\n",
    "# Cálculo del apartado 1\n",
    "p_gratis = p_gratis_no_spam * p_no_spam + p_gratis_spam*p_spam\n",
    "posterior_gratis = (p_gratis_spam * p_spam)/p_gratis\n",
    "\n",
    "# Cálculo del apartado 2\n",
    "p_gratis_oferta_spam = p_oferta_spam * p_gratis_spam\n",
    "p_gratis_oferta_no_spam = p_oferta_no_spam * p_gratis_no_spam\n",
    "p_gratis_oferta = p_gratis_oferta_spam * p_spam + p_gratis_oferta_no_spam * p_no_spam\n",
    "posterior_gratis_oferta = (p_gratis_oferta_spam * p_spam)/p_gratis_oferta\n",
    "\n",
    "print(f\"P(SPAM | 'gratis') = {posterior_gratis:.6f}  (~{100*posterior_gratis:.2f}%)\")\n",
    "print(f\"P(SPAM | 'gratis' y 'oferta') = {posterior_gratis_oferta:.6f}  (~{100*posterior_gratis_oferta:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5f9a0-6574-4cb1-b346-7952872481f4",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Probabilidad de jugar profesionalmente al baloncesto\n",
    "\n",
    "Ahora vamos a calcular la probabilidad de que una persona juegue profesionalmente al baloncesto dada su altura y su edad. La *probabilidad a priori* de que una persona sea **PRO** es del **1%**: $P(\\text{PRO})=0.01$. Asumiremos **independencia condicional** entre *edad* y *altura* dada la clase (al asumir independencia estamos calculando \"Naïve Bayes\"). Además, consideraremos que las características se modelan con distribuciones **gaussianas**.\n",
    "\n",
    "Estas son las verosimilitudes:\n",
    "\n",
    "- Si es **PRO**  \n",
    "  $\\text{edad}\\sim \\mathcal{N}(\\mu{=}27,\\ \\sigma^2{=}3^2)$,  \n",
    "  $\\text{altura (m)}\\sim \\mathcal{N}(\\mu{=}2.00,\\ \\sigma^2{=}0.07^2)$.\n",
    "- Si es **NO\\_PRO**  \n",
    "  $\\text{edad}\\sim \\mathcal{N}(\\mu{=}35,\\ \\sigma^2{=}10^2)$,  \n",
    "  $\\text{altura (m)}\\sim \\mathcal{N}(\\mu{=}1.72,\\ \\sigma^2{=}0.06^2)$.\n",
    "\n",
    "Calcula $P(\\text{PRO}\\mid \\text{edad},\\text{altura})$ para:\n",
    "\n",
    "1) Persona A: **edad = 25**, **altura = 1.95 m**.  \n",
    "2) Persona B: **edad = 30**, **altura = 1.90 m**.\n",
    "\n",
    "> **Pista:** como **asumimos independencia condicional**, la verosimilitud conjunta se obtiene **multiplicando** las densidades de cada característica.\n",
    "> $\\text{score}(\\text{PRO}) = P(\\text{PRO})\\cdot \\mathcal{N}(\\text{edad})\\cdot \\mathcal{N}(\\text{altura})$.  \n",
    "> Posterior $=\\dfrac{\\text{score}(\\text{PRO})}{\\text{score}(\\text{PRO}) + \\text{score}(\\text{NO\\_PRO})}$.\n",
    "\n",
    "Completa y ejecuta la celda de abajo. Además, justifica razonadamente el resultado que obtengas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae5708",
   "metadata": {},
   "source": [
    "--------------\n",
    "##### Apartado 1\n",
    "\n",
    "En este apartado tenemos que calcular $P(\\text{PRO }|\\text{ edad, altura})$ para una persona A, con edad 25 años y altura 1.95 m. Para calcularla, utilizamos la fórmula de probabilidad a posteriori dada por:\n",
    "$$P(\\text{PRO }|\\text{ edad, altura})=\\frac{\\text{score(PRO)}}{\\text{score(PRO)} + \\text{score(NO\\_PRO)}}$$\n",
    "Donde $\\text{score(PRO)} = P(\\text{PRO})\\cdot \\mathcal{N}(\\text{edad})\\cdot \\mathcal{N}(\\text{altura})$. Más en concreto, $\\mathcal{N}(\\text{X})$ es la probabilidad de la gaussiana correpondiente al suceso X de media y varianzas especificadas en el enunciado. Para obtener dicha probabilidad, hacemos uso de la función que nos facilita la práctica `gaussian_pdf(x,mu,var)` donde x es el suceso del que queremos saber la probabilidad, mu es la media y var la varianza la la distribución gaussiana.\n",
    "\n",
    "##### Apartado 2\n",
    "\n",
    "Este apartado es hacer lo mismo que en el anterior, pero para una persona B con edad 30 años y altura 1.9 metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c64dcf0-32e3-4fae-9e3e-22c55eb75162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(PRO | A) = 0.978639 (~97.86%)\n",
      "P(PRO | B) = 0.391573 (~39.16%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prior\n",
    "p_pro = 0.01\n",
    "p_no_pro = 1 - p_pro\n",
    "\n",
    "# Parámetros (medias y varianzas)\n",
    "mu_edad_pro, var_edad_pro = 27, 3**2\n",
    "mu_alt_pro,  var_alt_pro  = 2.00, 0.07**2\n",
    "\n",
    "mu_edad_no, var_edad_no = 35, 10**2\n",
    "mu_alt_no,  var_alt_no  = 1.72, 0.06**2\n",
    "\n",
    "# Candidatos\n",
    "edad_A, alt_A = 25, 1.95\n",
    "edad_B, alt_B = 30, 1.90\n",
    "\n",
    "def gaussian_pdf(x, mu, var):\n",
    "    return 1/np.sqrt(2*np.pi*var) * np.exp(-(x-mu)**2/(2*var))\n",
    "\n",
    "\n",
    "# Cáclulo de apartado 1\n",
    "score_proA = p_pro * gaussian_pdf(edad_A, mu_edad_pro, var_edad_pro) * gaussian_pdf(alt_A, mu_alt_pro, var_alt_pro)\n",
    "score_no_proA = p_no_pro * gaussian_pdf(edad_A, mu_edad_no, var_edad_no) * gaussian_pdf(alt_A, mu_alt_no, var_alt_no)\n",
    "posterior_personaA = score_proA / (score_proA + score_no_proA)\n",
    "\n",
    "\n",
    "# Cálculo de apartado 2\n",
    "\n",
    "score_proB = p_pro * gaussian_pdf(edad_B, mu_edad_pro, var_edad_pro) * gaussian_pdf(alt_B, mu_alt_pro, var_alt_pro)\n",
    "score_no_proB = p_no_pro * gaussian_pdf(edad_B, mu_edad_no, var_edad_no) * gaussian_pdf(alt_B, mu_alt_no, var_alt_no)\n",
    "posterior_personaB = score_proB / (score_proB + score_no_proB)\n",
    "\n",
    "print(f\"P(PRO | A) = {posterior_personaA:.6f} (~{100*posterior_personaA:.2f}%)\")\n",
    "print(f\"P(PRO | B) = {posterior_personaB:.6f} (~{100*posterior_personaB:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88422139-4a1f-4c7d-a812-06555fd89be4",
   "metadata": {},
   "source": [
    "## 2. Clasificador **Gaussian Naïve Bayes**\n",
    "\n",
    "Ahora vamos a implementar un clasificador basado en Naïve Bayes, que solo acepta características continuas. Para ello, la única librería que emplearemos será `numpy`. El clasificador **Gaussian Naïve Bayes** asume que las características son **independientes entre sí dada la clase** (por esa razón se llama \"naïve\") y modela cada característica con una **Gaussiana**.\n",
    "> **Nota:** Existen variantes de Naïve Bayes que emplean otras distribuciones según el tipo de dato (p. ej., Multinomial, Bernoulli), y también para datos continuos pueden usarse alternativas a la gaussiana.\n",
    "\n",
    "El conjunto de datos de entrada es $\\mathcal{D}=\\{\\mathbf{X}, \\mathbf{y}\\}$, donde $\\mathbf{X}=\\{\\mathbf{x}_1, ..., \\mathbf{x}_N\\}$, $\\mathbf{y} = \\{y_1,\\dots,y_N\\}$, $N$ es el número de datos, $\\mathbf{x}_i=(x_{i,1},\\dots,x_{i,D})$ y $D$ es el número de características.\n",
    "\n",
    "### `fit(X, y)`\n",
    "Método para ajustar el clasificador (realiza el entrenamiento). Primero estima los **priores** de clase $P(y{=}k)$ como la frecuencia de cada clase en el conjunto de entrenamiento. Después, para cada clase $k$ y característica $j$, calcula la **media** $\\mu_{j,k}$ y la **varianza** $\\sigma^2_{j,k}$ usando únicamente los datos de esa clase.\n",
    "\n",
    "- **Prior (frecuencia relativa):**\n",
    "  $$\n",
    "  P(y{=}k)=\\frac{n_k}{N}.\n",
    "  $$\n",
    "  (donde $n_k$ es el número de ejemplos de la clase $k$ y $N$ el total).\n",
    "\n",
    "> **Nota:** añade un $\\varepsilon$ pequeño a cada $\\sigma^2_{j,k}$ para evitar varianzas nulas.\n",
    "\n",
    "- **Salida:** el clasificador entrenado con las clases, los priors $\\{P(y{=}k)\\}$ y las matrices de medias $\\mu$ y varianzas $\\sigma^2$ de tamaño $(K\\times D)$.\n",
    "\n",
    "### `predict(X)`\n",
    "Método de predicción. Para cada nuevo dato $x_i$, calcula la *probabilidad a posteriori* de cada clase $P(y{=}k \\mid x_i)$ usando el prior y el producto de densidades Gaussianas por característica. Termina prediciendo la clase con mayor probabilidad.\n",
    "\n",
    "- **Puntuación por clase:**\n",
    "  $$\n",
    "  \\text{score}(k)= P(y{=}k)\\, \\prod_{j=1}^{D}\\mathcal{N}\\big(x_j;\\,\\mu_{j,k},\\,\\sigma^2_{j,k}\\big).\n",
    "  $$\n",
    "\n",
    "- **Salida:** la predicción final es la clase que tenga mayor score (probabilidad).\n",
    "  $$\n",
    "  y=\\arg\\max_{k}\\ \\text{score}(k).\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ddd6c8a1-e8f4-41df-a516-e686fdb95e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos librerias\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1116dc42-85de-4344-93e9-d1cf2c7c2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Cargar datos\n",
    "X_all, y_all = load_iris(return_X_y=True)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Dividimos el dataset entre train-test y validación (75-25)\n",
    "indices = np.random.permutation(len(y_all))\n",
    "cut = int(0.75 * len(y_all))\n",
    "indices_train, indices_validation = indices[:cut], indices[cut:]\n",
    "X_train, y_train = X_all[indices_train], y_all[indices_train]\n",
    "X_validation, y_validation = X_all[indices_validation], y_all[indices_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e2358-44ff-4d22-aa39-8aeec76380e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    \n",
    "    def __init__(self, eps=1e-8):\n",
    "        self.eps = eps\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Función que establece los datos dado un set de datos de entrenamiento\n",
    "        Args:\n",
    "            X: set de datos\n",
    "            y: set de labels\n",
    "        \"\"\"\n",
    "        # Vemos qué clases distintas hay\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        # Guardamos los datos del tamaño, num_obs es el número de observaciones, num_data número de datos y \n",
    "        # num_classes es el número de clases distintas\n",
    "        num_obs, num_data = X.shape\n",
    "        num_classes = len(self.classes)\n",
    "\n",
    "        self.priors = np.zeros(num_classes)\n",
    "        self.mu = np.zeros((num_classes, num_data))\n",
    "        self.var  = np.zeros((num_classes, num_data))\n",
    "\n",
    "        # Calculamos la probabilidad, como frecuencia del set de datos de entrenamiento\n",
    "        # A su vez, con los datos de la etiqueta i, calculamos la media y la varianza.\n",
    "        for i, cl in enumerate(self.classes):\n",
    "            X_i = X[y==cl]\n",
    "            self.priors[i]  = len(X_i)/num_obs\n",
    "            self.mu[i]      = X_i.mean(axis=0)\n",
    "            self.var[i]     = X_i.var(axis=0) + self.eps\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def gaussian_pdf(self, x, mu, var):\n",
    "        \"\"\"\n",
    "        Función que devuelve la probabilidad de x dada una distribución gaussiana de media mu y varianza var\n",
    "        \"\"\"\n",
    "        return 1/np.sqrt(2*np.pi*var) * np.exp(-(x-mu)**2/(2*var))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Función que predice las etiquetas de unos datos X\n",
    "        \"\"\"\n",
    "        num_obs, _ = X.shape\n",
    "        num_classes = len(self.classes)\n",
    "        scores = np.zeros((num_obs, num_classes))\n",
    "\n",
    "        # Iteramos por todas las observaciones\n",
    "        for i in range(num_obs):\n",
    "\n",
    "            # Luego por todas las etiquetas posibles, para calcular el score\n",
    "            for j in range(num_classes):\n",
    "                \n",
    "                # Como pone en el enunciado, el score del dato x para la etiqueta j es la probabilidad a priori de la etiqueta i\n",
    "                # por el producto de las probabilidades de la distribución gaussiana de cada elemento x_i dada la media y varianza \n",
    "                # del elemento i observado en los datos de entrenamiento\n",
    "                probabilities = np.prod(self.gaussian_pdf(X[i], self.mu[j], self.var[j]))\n",
    "                scores[i][j] = self.priors[j] * probabilities\n",
    "                \n",
    "        return self.classes[np.argmax(scores, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5938f9a0-ec7c-4548-b6c7-c236257e446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Precisión (validación en el 25% restante): 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y validar\n",
    "gnb = GaussianNaiveBayes().fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_validation)\n",
    "print(\"Precisión (validación en el 25% restante):\", (y_pred == y_validation).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d554c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.8 2.8 5.1 2.4]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.1 2.8 4.  1.3]] (112, 4)\n",
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2 1 0 2 1 1 1 1 2 0 0 2 1 0 0\n",
      " 1 0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0 0 0 1 2 2 0 0 0 1 1 0\n",
      " 0] 112\n",
      "112 4\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:10], X_train.shape)\n",
    "print(y_train, len(y_train))\n",
    "\n",
    "\n",
    "O,N = X_train.shape\n",
    "\n",
    "print(O,N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cb705372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n",
      "2\n",
      "[[2 3]\n",
      " [6 7]]\n",
      "[4. 5.]\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "datos_prueba = np.array([[2,3],[4,5],[6,7],[8,9]])\n",
    "prueba = np.array([1,2,1,2])\n",
    "idx = np.where(prueba == 1)[0]\n",
    "\n",
    "print(idx)\n",
    "print(len(idx))\n",
    "\n",
    "print(datos_prueba[idx])\n",
    "\n",
    "print((datos_prueba[idx].mean(axis=0)))\n",
    "\n",
    "print(max(datos_prueba[idx].mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce6482f0-a78f-42f1-9b7a-fdb3b9962061",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precisión (validación en el 25% restante): 0.9473684210526315"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

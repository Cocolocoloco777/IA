{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ea7978-87e1-4f62-941b-372adc4972f2",
   "metadata": {},
   "source": [
    "# Práctica de aprendizaje automático (parte 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995aeb7-cabe-4769-8892-fae24a8ac39c",
   "metadata": {},
   "source": [
    "# Teorema de Bayes y Naïve Bayes (1.5 puntos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50a1f4",
   "metadata": {},
   "source": [
    "## 1. Teorema de Bayes\n",
    "\n",
    "El **Teorema de Bayes**:\n",
    "$$\n",
    "P(H_1 \\mid D, I) = \\frac{P(D \\mid H_1, I) \\times P(H_1 \\mid I)}{P(D \\mid I)} \\quad \\text{con} \\quad P(D \\mid I) = \\sum_i P(D \\mid H_i, I) \\times P(H_i \\mid I).\n",
    "$$\n",
    "\n",
    "- **$H_1$** = Hipótesis 1, **$D$** = datos, **$I$** = información.\n",
    "\n",
    "- **$P(H_1 \\mid I)$**: Probabilidad a *priori* de la hipótesis 1 (antes de observar los datos).\n",
    "- **$P(D \\mid I)$**: Evidencia de los datos.\n",
    "- **$P(D \\mid H_1, I)$**: *Verosimilitud* de la hipótesis 1 dados los datos.\n",
    "- **$P(H_1 \\mid D, I)$**: Probabilidad a *posteriori* de la hipótesis 1 (después de observar los datos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57344cae",
   "metadata": {},
   "source": [
    "### Ejercicio 1 - Palabra sospechosa en correo\n",
    "Vamos a calcular la probabilidad de que un correo sea **SPAM** dadas las palabras **\"gratis\"** y **\"oferta\"**. Supongamos que dado un nuevo correo, la probabilidad a priori de que sea **SPAM** es del **20%**.\n",
    "\n",
    "Si aparece la palabra **\"gratis\"**:\n",
    "- $P(\\text{\"gratis\"}\\mid\\text{SPAM})=0.4$\n",
    "- $P(\\text{\"gratis\"}\\mid \\neg \\text{SPAM})=0.05$\n",
    "- \n",
    "Si aparece la palabra **\"oferta\"**:\n",
    "- $P(\\text{\"oferta\"}\\mid\\text{SPAM})=0.7$\n",
    "- $P(\\text{\"oferta\"}\\mid \\neg \\text{SPAM})=0.05$\n",
    "\n",
    "1. Calcula $P(\\text{SPAM}\\mid\\text{\"gratis\"})$.\n",
    "2. ¿Qué ocurre si además ves la palabra **\"oferta\"** y asumes independencia? (Pista: multiplica verosimilitudes.)\n",
    "\n",
    "\n",
    "Completa y ejecuta la celda de abajo. Además, justifica razonadamente el resultado que obtengas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95eaf55-ce4d-4511-8eab-69c2c2da50de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(SPAM | 'gratis') = 0.666667  (~66.67%)\n",
      "P(SPAM | 'gratis' y 'oferta') = 0.965517  (~96.55%)\n"
     ]
    }
   ],
   "source": [
    "p_spam = 0.2\n",
    "p_no_spam = 1 - p_spam\n",
    "\n",
    "p_gratis_spam = 0.4\n",
    "p_gratis_no_spam  = 0.05\n",
    "\n",
    "p_oferta_spam = 0.7\n",
    "p_oferta_no_spam  = 0.05\n",
    "\n",
    "# Tu código aquí\n",
    "# ...\n",
    "\n",
    "print(f\"P(SPAM | 'gratis') = {posterior_gratis:.6f}  (~{100*posterior_gratis:.2f}%)\")\n",
    "print(f\"P(SPAM | 'gratis' y 'oferta') = {posterior_gratis_oferta:.6f}  (~{100*posterior_gratis_oferta:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5f9a0-6574-4cb1-b346-7952872481f4",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Probabilidad de jugar profesionalmente al baloncesto\n",
    "\n",
    "Ahora vamos a calcular la probabilidad de que una persona juegue profesionalmente al baloncesto dada su altura y su edad. La *probabilidad a priori* de que una persona sea **PRO** es del **1%**: $P(\\text{PRO})=0.01$. Asumiremos **independencia condicional** entre *edad* y *altura* dada la clase (al asumir independencia estamos calculando \"Naïve Bayes\"). Además, consideraremos que las características se modelan con distribuciones **gaussianas**.\n",
    "\n",
    "Estas son las verosimilitudes:\n",
    "\n",
    "- Si es **PRO**  \n",
    "  $\\text{edad}\\sim \\mathcal{N}(\\mu{=}27,\\ \\sigma^2{=}3^2)$,  \n",
    "  $\\text{altura (m)}\\sim \\mathcal{N}(\\mu{=}2.00,\\ \\sigma^2{=}0.07^2)$.\n",
    "- Si es **NO\\_PRO**  \n",
    "  $\\text{edad}\\sim \\mathcal{N}(\\mu{=}35,\\ \\sigma^2{=}10^2)$,  \n",
    "  $\\text{altura (m)}\\sim \\mathcal{N}(\\mu{=}1.72,\\ \\sigma^2{=}0.06^2)$.\n",
    "\n",
    "Calcula $P(\\text{PRO}\\mid \\text{edad},\\text{altura})$ para:\n",
    "\n",
    "1) Persona A: **edad = 25**, **altura = 1.95 m**.  \n",
    "2) Persona B: **edad = 30**, **altura = 1.90 m**.\n",
    "\n",
    "> **Pista:** como **asumimos independencia condicional**, la verosimilitud conjunta se obtiene **multiplicando** las densidades de cada característica.\n",
    "> $\\text{score}(\\text{PRO}) = P(\\text{PRO})\\cdot \\mathcal{N}(\\text{edad})\\cdot \\mathcal{N}(\\text{altura})$.  \n",
    "> Posterior $=\\dfrac{\\text{score}(\\text{PRO})}{\\text{score}(\\text{PRO}) + \\text{score}(\\text{NO\\_PRO})}$.\n",
    "\n",
    "Completa y ejecuta la celda de abajo. Además, justifica razonadamente el resultado que obtengas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c64dcf0-32e3-4fae-9e3e-22c55eb75162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(PRO | A) = 0.978639 (~97.86%)\n",
      "P(PRO | B) = 0.391573 (~39.16%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prior\n",
    "p_pro = 0.01\n",
    "p_no_pro = 1 - p_pro\n",
    "\n",
    "# Parámetros (medias y varianzas)\n",
    "mu_edad_pro, var_edad_pro = 27, 3**2\n",
    "mu_alt_pro,  var_alt_pro  = 2.00, 0.07**2\n",
    "\n",
    "mu_edad_no, var_edad_no = 35, 10**2\n",
    "mu_alt_no,  var_alt_no  = 1.72, 0.06**2\n",
    "\n",
    "# Candidatos\n",
    "edad_A, alt_A = 25, 1.95\n",
    "edad_B, alt_B = 30, 1.90\n",
    "\n",
    "def gaussian_pdf(x, mu, var):\n",
    "    return 1/np.sqrt(2*np.pi*var) * np.exp(-(x-mu)**2/(2*var))\n",
    "\n",
    "# Tu código aquí\n",
    "# ...\n",
    "\n",
    "print(f\"P(PRO | A) = {posterior_personaA:.6f} (~{100*posterior_personaA:.2f}%)\")\n",
    "print(f\"P(PRO | B) = {posterior_personaB:.6f} (~{100*posterior_personaB:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88422139-4a1f-4c7d-a812-06555fd89be4",
   "metadata": {},
   "source": [
    "## 2. Clasificador **Gaussian Naïve Bayes**\n",
    "\n",
    "Ahora vamos a implementar un clasificador basado en Naïve Bayes, que solo acepta características continuas. Para ello, la única librería que emplearemos será `numpy`. El clasificador **Gaussian Naïve Bayes** asume que las características son **independientes entre sí dada la clase** (por esa razón se llama \"naïve\") y modela cada característica con una **Gaussiana**.\n",
    "> **Nota:** Existen variantes de Naïve Bayes que emplean otras distribuciones según el tipo de dato (p. ej., Multinomial, Bernoulli), y también para datos continuos pueden usarse alternativas a la gaussiana.\n",
    "\n",
    "El conjunto de datos de entrada es $\\mathcal{D}=\\{\\mathbf{X}, \\mathbf{y}\\}$, donde $\\mathbf{X}=\\{\\mathbf{x}_1, ..., \\mathbf{x}_N\\}$, $\\mathbf{y} = \\{y_1,\\dots,y_N\\}$, $N$ es el número de datos, $\\mathbf{x}_i=(x_{i,1},\\dots,x_{i,D})$ y $D$ es el número de características.\n",
    "\n",
    "### `fit(X, y)`\n",
    "Método para ajustar el clasificador (realiza el entrenamiento). Primero estima los **priores** de clase $P(y{=}k)$ como la frecuencia de cada clase en el conjunto de entrenamiento. Después, para cada clase $k$ y característica $j$, calcula la **media** $\\mu_{j,k}$ y la **varianza** $\\sigma^2_{j,k}$ usando únicamente los datos de esa clase.\n",
    "\n",
    "- **Prior (frecuencia relativa):**\n",
    "  $$\n",
    "  P(y{=}k)=\\frac{n_k}{N}.\n",
    "  $$\n",
    "  (donde $n_k$ es el número de ejemplos de la clase $k$ y $N$ el total).\n",
    "\n",
    "> **Nota:** añade un $\\varepsilon$ pequeño a cada $\\sigma^2_{j,k}$ para evitar varianzas nulas.\n",
    "\n",
    "- **Salida:** el clasificador entrenado con las clases, los priors $\\{P(y{=}k)\\}$ y las matrices de medias $\\mu$ y varianzas $\\sigma^2$ de tamaño $(K\\times D)$.\n",
    "\n",
    "### `predict(X)`\n",
    "Método de predicción. Para cada nuevo dato $x_i$, calcula la *probabilidad a posteriori* de cada clase $P(y{=}k \\mid x_i)$ usando el prior y el producto de densidades Gaussianas por característica. Termina prediciendo la clase con mayor probabilidad.\n",
    "\n",
    "- **Puntuación por clase:**\n",
    "  $$\n",
    "  \\text{score}(k)= P(y{=}k)\\, \\prod_{j=1}^{D}\\mathcal{N}\\big(x_j;\\,\\mu_{j,k},\\,\\sigma^2_{j,k}\\big).\n",
    "  $$\n",
    "\n",
    "- **Salida:** la predicción final es la clase que tenga mayor score (probabilidad).\n",
    "  $$\n",
    "  y=\\arg\\max_{k}\\ \\text{score}(k).\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd6c8a1-e8f4-41df-a516-e686fdb95e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos librerias\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1116dc42-85de-4344-93e9-d1cf2c7c2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Cargar datos\n",
    "X_all, y_all = load_iris(return_X_y=True)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Dividimos el dataset entre train-test y validación (75-25)\n",
    "indices = np.random.permutation(len(y_all))\n",
    "cut = int(0.75 * len(y_all))\n",
    "indices_train, indices_validation = indices[:cut], indices[cut:]\n",
    "X_train, y_train = X_all[indices_train], y_all[indices_train]\n",
    "X_validation, y_validation = X_all[indices_validation], y_all[indices_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07e2358-44ff-4d22-aa39-8aeec76380e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completa la clase GaussianNaiveBayes\n",
    "class GaussianNaiveBayes:\n",
    "    \n",
    "    def __init__(self, eps=1e-8):\n",
    "        self.eps = eps\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.classes = # Tu código aquí\n",
    "        counts       = # Tu código aquí\n",
    "        self.priors  = # Tu código aquí\n",
    "        self.mu      = # Tu código aquí\n",
    "        self.var     = # Tu código aquí (recuerda añadir un pequeño epsilon)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        # TODO: usa self.priors, self.mu, self.var para calcular 'scores' y predice la clase con mayor score para cada fila de X\n",
    "        # Tu código aquí\n",
    "        return np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5938f9a0-ec7c-4548-b6c7-c236257e446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión (validación en el 25% restante): 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y validar\n",
    "gnb = GaussianNaiveBayes().fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_validation)\n",
    "print(\"Precisión (validación en el 25% restante):\", (y_pred == y_validation).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6482f0-a78f-42f1-9b7a-fdb3b9962061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
